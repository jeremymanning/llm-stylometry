% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

%% Journal article

@article{NiloEtal99,
title = {The Application of Principal
Component Analysis to Stylometry},
journal = {Literary and Linguistic Computing},
volume = {14},
number = {4},
pages = {445--465},
year = {1999},
author = {Jose Nilo G. Binongo and M. W. A. Smith}}

@article{NiloBino03,
author = {José Nilo G. Binongo},
title = {Who Wrote the 15th Book of {O}z? {A}n Application of Multivariate Analysis to Authorship Attribution},
journal = {CHANCE},
volume = {16},
number = {2},
pages = {9--17},
year = {2003},
publisher = {ASA Website},
doi = {10.1080/09332480.2003.10554843},
URL = {  https://doi.org/10.1080/09332480.2003.10554843},
eprint = { https://doi.org/10.1080/09332480.2003.10554843}}


@inproceedings{IppoEtal20,
    title = "Automatic Detection of Generated Text is Easiest when Humans are Fooled",
    author = "Ippolito, Daphne  and
      Duckworth, Daniel  and
      Callison-Burch, Chris  and
      Eck, Douglas",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.164",
    doi = "10.18653/v1/2020.acl-main.164",
    pages = "1808--1822",
    abstract = "Recent advancements in neural language modelling make it possible to rapidly generate vast amounts of human-sounding text. The capabilities of humans and automatic discriminators to detect machine-generated text have been a large source of research interest, but humans and machines rely on different cues to make their decisions. Here, we perform careful benchmarking and analysis of three popular sampling-based decoding strategies{---}top-{\_}k{\_}, nucleus sampling, and untruncated random sampling{---}and show that improvements in decoding methods have primarily optimized for fooling humans. This comes at the expense of introducing statistical abnormalities that make detection easy for automatic systems. We also show that though both human and automatic detector performance improve with longer excerpt length, even multi-sentence excerpts can fool expert human raters over 30{\%} of the time. Our findings reveal the importance of using both human and automatic detectors to assess the humanness of text generation systems.",
}

@misc{SadaEtal24,
      title={Can AI-Generated Text be Reliably Detected?}, 
      author={Vinu Sankar Sadasivan and Aounon Kumar and Sriram Balasubramanian and Wenxiao Wang and Soheil Feizi},
      year={2024},
      eprint={2303.11156},
      archivePrefix={arXiv},
      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}

@inproceedings{UndeEtal13,
   title={Mapping mutable genres in structurally complex volumes},
   url={http://dx.doi.org/10.1109/BigData.2013.6691676},
   DOI={10.1109/bigdata.2013.6691676},
   booktitle={2013 IEEE International Conference on Big Data},
   publisher={IEEE},
   author={Underwood, Ted and Black, Michael L. and Auvil, Loretta and Capitanu, Boris},
   year={2013},
   month=oct, pages={95–103} }

@article{Mikr25,
    author = {Mikros, George},
    title = {Beyond the surface: stylometric analysis of {G}{P}{T}-4o’s capacity for literary style imitation},
    journal = {Digital Scholarship in the Humanities},
    pages = {587--600},
    volume = {40},
    year = {2025},
    month = {04},
    abstract = {This study aims to explore the ability of GPT-4o to imitate the literary style of renowned authors. Ernest Hemingway and Mary Shelley were selected due to their contrasting literary styles and their overall impact on world literature. Using three distinct prompting strategies—zero-shot generation, zero-shot imitation, and in-context learning—we generated forty-five stylistic imitations and analyzed them alongside the authors’ original texts. To ensure thematic consistency, we constrained the generated texts to shared narrative themes derived from the authors’ works. We used a distance-based approach to authorship attribution using the 1,000 most frequent words and cosine distance to explore how the large language model’s imitations were positioned in the multidimensional authorship space. Moreover, we exploited a random forest classifier and repeated the authorship attribution task to analyze the authorship distinctiveness of the GPT imitations further. We used a combination of Textual Complexity and Readability, Author Multilevel N-gram Profiles, Word Embeddings, and Linguistic Inquiry and Word Count features. t-SNE visualizations further evaluated the stylistic alignment between original and GPT-generated texts. The findings reveal that while GPT-4o captures some surface-level stylistic elements of the authors, it struggles to fully replicate the depth and uniqueness of their stylometric signatures. Imitations generated via in-context learning showed improved alignment with the original authors but still exhibited significant overlap with generic GPT outputs.},
    issn = {2055-7671},
    doi = {10.1093/llc/fqaf035},
    url = {https://doi.org/10.1093/llc/fqaf035},
    eprint = {https://academic.oup.com/dsh/advance-article-pdf/doi/10.1093/llc/fqaf035/62995095/fqaf035.pdf},
}





@inproceedings{Reza25,
    title = "Detecting, Generating, and Evaluating in the Writing Style of Different Authors",
    author = "Rezaei, Mosab",
    editor = "Ebrahimi, Abteen  and
      Haider, Samar  and
      Liu, Emmy  and
      Haider, Sammar  and
      Leonor Pacheco, Maria  and
      Wein, Shira",
    booktitle = "Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 4: Student Research Workshop)",
    month = apr,
    year = "2025",
    address = "Albuquerque, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.naacl-srw.47/",
    pages = "485--491",
    ISBN = "979-8-89176-192-6"
}



@article{WebeEtal23,
title = {Testing of detection tools for AI-generated text},
journal = {International Journal for Educational Integrity},
volume = {19},
number = {26},
year = {2023},
doi = {https://doi.org/10.1007/s40979-023-00146-z},
author = {Debora Weber-Wulff and  Alla Anohina-Naumeca and  Sonja Bjelobaba and  Tomáš Foltýnek and  Jean Guerrero-Dib and  Olumide Popoola and  Petr Šigut and Lorna Waddington }
}


@article{WangEtal15,
title = {The Uncanny Valley: Existence and Explanations},
journal = {Review of General Psychology },
volume = {9},
number = {4},
pages = {393--407},
year = {2015},
author = {Shensheng Wang and  Scott O. Lilienfeld and Philippe Rochat}}


@article{Holm98,
title = {The evolution of stylometry
in humanities scholarship},
journal = {Literary and Linguistic
Computing},
volume = {13},
number = {3},
pages = {111–-117},
year = {1998},
author = {David I Holmes}}


@article{Carl16,
title = {A Quantitative Analysis of Writing Style on the {U}.{S}. {S}upreme {C}ourt},
journal = {Wash. U. L. Rev.},
volume = {93},
number = {6},
pages = {1461},
year = {2016},
author = {Keith Carlson and Michael A. Livermore and Daniel Rockmore}}

@article{DesaEtal23a,
title = {Accurately detecting {AI} text when {ChatGPT} is told to write like a chemist},
journal = {Cell Reports Physical Science},
volume = {4},
number = {11},
pages = {101672},
year = {2023},
issn = {2666-3864},
doi = {https://doi.org/10.1016/j.xcrp.2023.101672},
url = {https://www.sciencedirect.com/science/article/pii/S2666386423005015},
author = {Heather Desaire and Aleesa E. Chua and Min-Gyu Kim and David Hua}}


@article{DesaEtal23b,
title = {Distinguishing academic science writing from humans or {ChatGPT} with over 99\% accuracy using off-the-shelf machine learning tools},
journal = {Cell Reports Physical Science},
volume = {4},
number = {6},
pages = {101426},
year = {2023},
issn = {2666-3864},
doi = {https://doi.org/10.1016/j.xcrp.2023.101426},
url = {https://www.sciencedirect.com/science/article/pii/S266638642300200X},
author = {Heather Desaire and Aleesa E. Chua and Madeline Isom and Romana Jarosova and David Hua},
keywords = {ChatGPT, AI, machine learing, text analysis, XGBoost, plagiarism}}

@article{Well23,
title = {Machine-Learning Tool Easily Spots {C}hat{GPT}’s Writing},
journal = {IEEE Spectrum},
month = {June},
year = {2023},
url = {https://spectrum.ieee.org/chatgpt-2661369022},
author = {Sarah Wells}}

@ONLINE{GPTZero,
  title = {GPTZero},
  url = {https://gptzero.me/},
  urldate = {2023-12-19}
}

@article{LoshHutt17,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2017},
      volume={1711.05101},
      journal={arXiv},
      url={https://arxiv.org/abs/1711.05101}, 
}

@article{TempEtal17,
author = {Neal, Tempestt and Sundararajan, Kalaivani and Fatima, Aneez and Yan, Yiming and Xiang, Yingfei and Woodard, Damon},
title = {Surveying Stylometry Techniques and Applications},
year = {2017},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3132039},
doi = {10.1145/3132039},
abstract = {The analysis of authorial style, termed stylometry, assumes that style is quantifiably measurable for evaluation of distinctive qualities. Stylometry research has yielded several methods and tools over the past 200 years to handle a variety of challenging cases. This survey reviews several articles within five prominent subtasks: authorship attribution, authorship verification, authorship profiling, stylochronometry, and adversarial stylometry. Discussions on datasets, features, experimental techniques, and recent approaches are provided. Further, a current research challenge lies in the inability of authorship analysis techniques to scale to a large number of authors with few text samples. Here, we perform an extensive performance analysis on a corpus of 1,000 authors to investigate authorship attribution, verification, and clustering using 14 algorithms from the literature. Finally, several remaining research challenges are discussed, along with descriptions of various open-source and commercial software that may be useful for stylometry subtasks.},
journal = {ACM Comput. Surv.},
month = {Nov},
articleno = {86},
numpages = {36},
keywords = {Adversarial stylometry, stylometry, authorship analysis}
}

@article{Juol08, 
author = {Juola, Patrick},
title = { Authorship Attribution}, 
volume = {1}, 
year = {2008},
number = {3}, 
journal = {Foundations and Trends  in Information Retrieval},
pages = {233--334} 
}
@article{Howl91,
	author = {Jacob Howland},
	year = "1991",
	title = {Re-Reading {P}lato: The Problem of {P}latonic Chronology},
	journal = {Phoenix},
	volume = "45",
	number = "3",
	pages = "189--214"
}

@misc{VaswEtal23,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@book{Ginz66,
    author  = {Ginzburg, R.S.},
    title   = {A Course in Modern English Lexicology},
    year    = "1966",
    publisher = {Higher School %Publishing House},
  url = {https://books.google.com/books?id=AaQASwAACAA}
}

@ONLINE{Davi08,
  author = {Davies, M.},
  title = {Word frequency data from The Corpus of Contemporary American English},
  month = {},
  year = {2008},
  url = {https://www.wordfrequency.info},
  urldate = {2023-12-19}
}

@misc{DevlEtal19,
        title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@misc{FanEtal18,
 title = "Hierarchical Neural Story Generation",
    author = "Fan, Angela  and
      Lewis, Mike  and
      Dauphin, Yann",
    editor = "Gurevych, Iryna  and
      Miyao, Yusuke",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1082",
    doi = "10.18653/v1/P18-1082",
    pages = "889--898",
    abstract = "We explore story generation: creative systems that can build coherent and fluent passages of text about a topic. We collect a large dataset of 300K human-written stories paired with writing prompts from an online forum. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong baselines on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one.",
}


@article{HughEtal12,
	author = {James M. Hughes and Nicholas J. Foti and David C. Krakauer  and Daniel N. Rockmore},
	year = "2012",
	title = {Quantitative patterns of stylistic influence in the evolution of literature},
	journal = {PNAS},
	volume = "109",
	number = "20",
	pages = "7682--7686",
	doi = "https://doi.org/10.1073/pnas.1115407109",
}

@book{GeddEtal92,
  author		= "Geddes, K. O. and Czapor, S. R. and Labahn, G.",
  title			= "Algorithms for {C}omputer {A}lgebra",
  address		= "Boston",
  publisher		= "Kluwer",
  year			= "1992"
}

@book{Luto97,
    author  = "Lutos{\l}awski, W.",
    title   = "The Origin and Growth of Plato's Logic: With an Account of Plato's Style and of the Chronology of His Writings",
    publisher = "WC Brown Reprint Library",
address		= "London",
    year    = "1897" 
}

@article{More00,
author = {Moretti, Franco},
year = {2000},
title = {Conjectures on World Literature},
journal = {New Left Review},
volume = {1},
month = {January},
pages = {54-68}}

@book{More17,
    author  = "Moretti, Franco",
    title   = "Graphs, Maps, Trees: Abstract Models for Literary History",
    year    = "2017",
    address = "Brookly, NY",
    publisher = "Verso Books"
}

@article{MostWall63,
	author = { Frederick Mosteller  and David L. Wallace},
	year = "1963",
	title = {Inference in an Authorship Problem},
	journal = {Journal of the American Statistical Association},
	volume = "58",
	number = "302",
	pages = "275--309",
	doi = "https://doi.org/10.2307/2283270",
}


@book{MostWall84,
    author  = {Frederick Mosteller  and David L. Wallace},
    title   = {Applied Bayesian and Classical Inference: The Case of the Federalist Papers},
    year    = "1984",
    publisher = {Addison-Wesley},
    address = {Reading, MA}
}

@article{CampGear95,
  author		= "Campbell, S. L. and Gear, C. W.",
  title			= "The index of general nonlinear {D}{A}{E}{S}",
  journal		= "Numer. {M}ath.",
  volume		= "72",
  number		= "2",
  pages			= "173--196",
  year			= "1995"
}


@misc{HamnEtal12,
    author = {Ben Hamner, Jaison Morgan, lynnvandev, Mark Shermis, Tom Vander Ark},
    title = {The Hewlett Foundation: Automated Essay Scoring},
    publisher = {Kaggle},
    year = {2012},
    url = {https://kaggle.com/competitions/asap-aes}
}

@misc{OSheND,
    author = {Jim O'Shea},
    title = {Function word lists},
    publisher = {Jim O'Shea},
    year = {n.d.},
    url = {https://semanticsimilarity.wordpress.com/wp-content/uploads/2013/08/jim-oshea-fwlist-277.pdf}
}

@book{AhoUllm72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{ChanEtal81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{AndrJian07,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusf97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{RasoTetr15,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{AndoZhan05,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}


@article{NealEtal17,
  title={Surveying stylometry techniques and applications},
  author={Neal, Tempestt and Sundararajan, Kalaivani and Fatima, Aneez and Yan, Yiming and Xiang, Yingfei and Woodard, Damon},
  journal={ACM Computing Surveys (CSuR)},
  volume={50},
  number={6},
  pages={1--36},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{RadfEtal19,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{Krus64,
  title={Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis},
  author={Kruskal, Joseph B},
  journal={Psychometrika},
  volume={29},
  number={1},
  pages={1--27},
  year={1964},
  publisher={Springer-Verlag}
}

@inproceedings{KumaLiu23,
  title={Neural authorship attribution: Stylometric analysis on large language models},
  author={Kumarage, Tharindu and Liu, Huan},
  booktitle={2023 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)},
  pages={51--54},
  year={2023},
  organization={IEEE}
}

@article{HuanEtal25,
  author = {Huang, W. and Murakami, A. and Grieve, J.},
  title = {Attributing authorship via the perplexity of authorial language models},
  journal = {PLOS One},
  volume = {20},
  number = {7},
  pages = {e0327081},
  year = {2025},
  doi = {10.1371/journal.pone.0327081}
}

@inproceedings{UcheEtal20,
  author = {Uchendu, Adaku and Le, Thai and Shu, Kai and Lee, Dongwon},
  title = {Authorship Attribution for Neural Text Generation},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages = {8384--8395},
  year = {2020},
  doi = {10.18653/v1/2020.emnlp-main.673}
}

@article{JuolBaay05,
  author = {Juola, Patrick and Baayen, Harald},
  title = {A controlled-corpus experiment in authorship identification by cross-entropy},
  journal = {Literary and Linguistic Computing},
  volume = {20},
  number = {Suppl},
  pages = {59--67},
  year = {2005},
  doi = {10.1093/llc/fqi024}
}

@inproceedings{ZhaoEtal06,
  author = {Zhao, Ying and Zobel, Justin and Vines, Phil},
  title = {Using Relative Entropy for Authorship Attribution},
  booktitle = {Information Retrieval Technology: Third Asia Information Retrieval Symposium, AIRS 2006},
  series = {LNCS},
  volume = {4182},
  pages = {92--105},
  year = {2006},
  publisher = {Springer},
  doi = {10.1007/11880592_8}
}

@inproceedings{FabiEtal20,
  author = {Fabien, Maël and Villatoro-Tello, Esaú and Motlicek, Petr and Parida, Shantipriya},
  title = {{BertAA}: {BERT} fine-tuning for Authorship Attribution},
  booktitle = {Proceedings of the 17th International Conference on Natural Language Processing (ICON)},
  pages = {127--137},
  year = {2020},
  url = {https://aclanthology.org/2020.icon-main.16/}
}

@book{UndeEtal19,
  author = {Underwood, Ted},
  title = {Distant Horizons: Digital Evidence and Literary Change},
  year = {2019},
  publisher = {University of Chicago Press},
  address = {Chicago, IL}
}

@article{TyoEtal22,
  author = {Tyo, Jacob and Dhingra, Bhuwan and Lipton, Zachary C.},
  title = {On the State of the Art in Authorship Attribution and Authorship Verification},
  journal = {arXiv},
  pages = {2209.06869},
  year = {2022}
}

@article{FincBosc24,
  author = {S Fincke and E Boschee},
  title = {Separating Style from Substance: Enhancing Cross-Genre Authorship Attribution through Data Selection and Presentation},
  journal = {arXiv preprint arXiv:2408.05192},
  year = {2024}
}

@article{SchuEtal20,
  author = {Schuster, Tal and Schuster, Roei and Shah, Darsh J. and Barzilay, Regina},
  title = {The Limitations of Stylometry for Detecting Machine-Generated Fake News},
  journal = {Computational Linguistics},
  volume = {46},
  number = {2},
  pages = {499--510},
  year = {2020}
}

@inproceedings{BarlStam20,
  author = {Barlas, Georgios and Stamatatos, Efstathios},
  title = {Cross-Domain Authorship Attribution Using Pre-trained Language Models},
  booktitle = {Artificial Intelligence Applications and Innovations},
  publisher = {Springer},
  year = {2020},
  pages = {255--266}
}

@inproceedings{QuirMaie19,
  author = {Quiring, Erwin and Maier, Alwin and Rieck, Konrad},
  title = {Misleading Authorship Attribution of Source Code using Adversarial Learning},
  booktitle = {Proceedings of the 28th USENIX Security Symposium},
  pages = {479--496},
  year = {2019}
}

@inproceedings{HoulEtal19,
  author = {Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  title = {Parameter-Efficient Transfer Learning for {NLP}},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages = {2790--2799},
  year = {2019}
}

@article{PedrEtal11,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@inproceedings{BirdLope04,
    title = {{NLTK}: The Natural Language Toolkit},
    author = {Bird, Steven  and Loper, Edward},
    booktitle = {Proceedings of the {ACL} Interactive Poster and Demonstration Sessions},
    year = {2004},
    address = {Barcelona, Spain},
    publisher = {Association for Computational Linguistics},
    pages = {214--217}
}